{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paige Haring\n",
    "\n",
    "peh40@pitt.edu\n",
    "\n",
    "10/16/17\n",
    "\n",
    "This notebook is my progress following along with this tutorial on scikit-learn.org: http://scikit-learn.org/dev/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import nltk\n",
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting directory to where my nltk data has the movie reviews corpus\n",
    "nltk.data.path #gotta find it first...\n",
    "movie_dir = \"/Users/Paige/nltk_data/corpora/movie_reviews/\"\n",
    "\n",
    "#load all of the files in the movie_reviews corpus as training data\n",
    "movie_train = load_files(movie_dir, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.datasets.base.Bunch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What is movie_train?\n",
    "type(movie_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'filenames', 'target', 'target_names']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(movie_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_train.target_names #These are the labels or classes we will want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/Users/Paige/nltk_data/corpora/movie_reviews/neg/cv405_21868.txt',\n",
       "       '/Users/Paige/nltk_data/corpora/movie_reviews/pos/cv190_27052.txt',\n",
       "       '/Users/Paige/nltk_data/corpora/movie_reviews/pos/cv132_5618.txt',\n",
       "       ...,\n",
       "       '/Users/Paige/nltk_data/corpora/movie_reviews/pos/cv653_19583.txt',\n",
       "       '/Users/Paige/nltk_data/corpora/movie_reviews/neg/cv559_0057.txt',\n",
       "       '/Users/Paige/nltk_data/corpora/movie_reviews/neg/cv684_12727.txt'], \n",
       "      dtype='<U64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_train.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many reviews do we have?\n",
    "len(movie_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"any remake of an alfred hitchcock film is at best an uncertain project , as a perfect murder illustrates . \\nfrankly , dial m for murder is not one of the master director's greatest efforts , so there is ample room for improvement . \\nunfortunately , instead of updating the script , ironing out some of the faults , and speeding up the pace a little , a perfect murder has inexplicably managed to eliminate almost everything that was worthwhile about dial m for murder , leaving behind the nearly- unw\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's look at the last review and the information we have about it.\n",
    "movie_train.data[-1][:500]\n",
    "\n",
    "#Seems like it's about the film Dial M for Murder and it doesn't look too good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_train.target[-1] #Yep. That's negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer & TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "pprint%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents = ['Hello, how are you today and how are your dogs?', 'Just fine!', 'How are the wife and kids?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We are forcing CountVectorizer to use nltk's word tokenizer because it's better for us. It doesn't ignore stopwords and punctuation like the default does.\n",
    "foovec = CountVectorizer(min_df=1, tokenizer=nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit_transform in module sklearn.feature_extraction.text:\n",
      "\n",
      "fit_transform(raw_documents, y=None) method of sklearn.feature_extraction.text.CountVectorizer instance\n",
      "    Learn the vocabulary dictionary and return term-document matrix.\n",
      "    \n",
      "    This is equivalent to fit followed by transform, but more efficiently\n",
      "    implemented.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    raw_documents : iterable\n",
      "        An iterable which yields either str, unicode or file objects.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    X : array, [n_samples, n_features]\n",
      "        Document-term matrix.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(foovec.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 7, ',': 1, 'how': 8, 'are': 4, 'you': 14, 'today': 12, 'and': 3, 'your': 15, 'dogs': 5, '?': 2, 'just': 9, 'fine': 6, '!': 0, 'the': 11, 'wife': 13, 'kids': 10}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sents_sounts is a word vector with infomation about the word frequencies for each sent in sents\n",
    "sents_counts = foovec.fit_transform(sents)\n",
    "\n",
    "#Calling fit_transform modified foovec\n",
    "#foovec now has an attribute called vocabulary that is kind of like a dictionary. The keys are the unique tokens\n",
    "#The values are a unique, numerical id\n",
    "foovec.vocabulary_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sents_counts has a dimension of 3 (document count) by 14 (# of unique words)\n",
    "sents_counts.shape\n",
    "\n",
    "#Note these 14 elements correspond to the id in foovec.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x16 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 20 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 2, 1, 0, 1, 2, 0, 0, 0, 1, 0, 1, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_counts.toarray()\n",
    "#Example:\n",
    "#The indexes with ones in the first list are 1, 2, 4, 6, 7, 11, 13\n",
    "#Those id's correspond to the words: ',', '?', 'are', 'hello', 'how', 'today', 'you'\n",
    "#Those are the words in the first sentence! sents_counts is essentially an inventory of which of the total number of words in sents\n",
    "#are in each sentence in sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert raw frequency counts into TF-IDF (Term Frequency -- Inverse Document Frequency) values\n",
    "\n",
    "#TF_IDF helps us figure out which words are the most important in each document in our corpus\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "sents_tfidf = tfidf_transformer.fit_transform(sents_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.29130889,  0.22154792,  0.22154792,  0.44309583,\n",
       "         0.29130889,  0.        ,  0.29130889,  0.44309583,  0.        ,\n",
       "         0.        ,  0.        ,  0.29130889,  0.        ,  0.29130889,\n",
       "         0.29130889],\n",
       "       [ 0.57735027,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.57735027,  0.        ,  0.        ,  0.57735027,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.        ,  0.32992832,  0.32992832,  0.32992832,\n",
       "         0.        ,  0.        ,  0.        ,  0.32992832,  0.        ,\n",
       "         0.43381609,  0.43381609,  0.        ,  0.43381609,  0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF values\n",
    "# raw counts have been normalized against document length, \n",
    "# terms that are found across many docs are weighted down\n",
    "# They aren't stopwords, but since they are found across docs, they aren't going to help us classify\n",
    "# This keeps document specific keywords weighted high!\n",
    "\n",
    "sents_tfidf.toarray()\n",
    "\n",
    "# We see in sentence two, id 0 = '!' has one of the highest weights because it is found only in that document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Movie Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize movie_vector object, and then turn movie train data into a vector \n",
    "movie_vec = CountVectorizer(min_df=2, tokenizer=nltk.word_tokenize)         # use all 25K words. 82.2% acc.\n",
    "movie_counts = movie_vec.fit_transform(movie_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 25313)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_vec.vocabulary_ #Wow that's big\n",
    "movie_counts.shape\n",
    "#There are 2000 entries and a total of 25,313 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert raw frequency counts into TF-IDF values so the important words are paid attention to\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "movie_tfidf = tfidf_transformer.fit_transform(movie_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 25313)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This has the same dimensions as movie_counts, but it is no longer raw frequency counts\n",
    "#Now, these are the weights of the words, where a high weight corresponds to a word that isn't frequent across docs\n",
    "#These words are \"important\"\n",
    "movie_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    movie_tfidf, movie_train.target, test_size = 0.20, random_state = 12)\n",
    "\n",
    "#set random state so we can replicate the same randomization next time we run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the classifier with the training documents and their targets\n",
    "clf = MultinomialNB().fit(docs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results, find accuracy\n",
    "y_pred = clf.predict(docs_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82250000000000001"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How good is our classifier at classifying?\n",
    "sklearn.metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[176,  30],\n",
       "       [ 41, 153]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I really don't know what this step entails..\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on my roommate's review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_new= ['This movie sucked.', \n",
    "          \"Tom Cruise's performance is as wooden as the plank of wood from edd ed and eddy.\", \n",
    "          'The writing was incredibly breathtaking despite the terrible delivery.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_new_counts = movie_vec.transform(reviews_new)\n",
    "reviews_new_tfidf = tfidf_transformer.transform(reviews_new_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = clf.predict(reviews_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'This movie sucked.' => neg\n",
      "\"Tom Cruise's performance is as wooden as the plank of wood from edd ed and eddy.\" => pos\n",
      "'The writing was incredibly breathtaking despite the terrible delivery.' => neg\n"
     ]
    }
   ],
   "source": [
    "# print out results\n",
    "for review, category in zip(reviews_new, pred):\n",
    "    print('%r => %s' % (review, movie_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# very short and fake movie reviews\n",
    "reviews_new = ['This movie was excellent', 'Absolute joy ride', \n",
    "            'Steven Seagal was terrible', 'Steven Seagal shined through.', \n",
    "              'This was certainly a movie', 'Two thumbs up', 'I fell asleep halfway through', \n",
    "              \"We can't wait for the sequel!!\", '!', '?', 'I cannot recommend this highly enough', \n",
    "              'instant classic.', 'Steven Seagal was amazing. His performance was Oscar-worthy.']\n",
    "reviews_new_counts = movie_vec.transform(reviews_new)\n",
    "reviews_new_tfidf = tfidf_transformer.transform(reviews_new_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# have classifier make a prediction\n",
    "pred = clf.predict(reviews_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'This movie was excellent' => pos\n",
      "'Absolute joy ride' => pos\n",
      "'Steven Seagal was terrible' => neg\n",
      "'Steven Seagal shined through.' => neg\n",
      "'This was certainly a movie' => neg\n",
      "'Two thumbs up' => neg\n",
      "'I fell asleep halfway through' => neg\n",
      "\"We can't wait for the sequel!!\" => neg\n",
      "'!' => neg\n",
      "'?' => neg\n",
      "'I cannot recommend this highly enough' => pos\n",
      "'instant classic.' => pos\n",
      "'Steven Seagal was amazing. His performance was Oscar-worthy.' => neg\n"
     ]
    }
   ],
   "source": [
    "# print out results\n",
    "for review, category in zip(reviews_new, pred):\n",
    "    print('%r => %s' % (review, movie_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting that the Steven Seagal reviews are never positive. Last sememster in LING1330, we used NLTK's Naive Bayes Classifier. The same thing happened then! That is because the Naive Bayes Classifier uses the same Naive Bayes formula. Our NLTK classifier uses a kitchen sink strategy. Steven Segal must signify a negative review because 'Steven' and 'Seagal' are not common across the entire corpus, but show up mainly in negative reviews, giving them a strong weight towards negative reviews. In the NLTK classifier, we don't do the TF-IDF change that we do here with sklearn. We also don't use a raw count. We use true or false values. We only care if word is present in that document, or it is not. In the sklearn classifer, the counts seem to give our classifier more information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
