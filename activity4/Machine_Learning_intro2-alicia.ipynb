{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning 2\n",
    "Na-Rae Han, 10/19/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General machine learning work flow:\n",
    "1. Choose a class of model\n",
    "2. Choose model hyperparameters\n",
    "3. Fit the model to the training data (\"training\")\n",
    "4. Use the model to predict labels for new data\n",
    "    - If labels are known (test data, aka 'gold' data), evaluate the performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three types of ML:\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/05.01-what-is-machine-learning.html\n",
    "\n",
    "1. Regression: predicting continuous values\n",
    "2. Classification: predicting discrete labels\n",
    "3. **Clustering: inferring labels on unlabeled data**  <-- This one below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "# Turns on/off pretty printing \n",
    "%pprint\n",
    "\n",
    "# Every returned Out[] is displayed, not just the last one. \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn               # sklearn is the ML package we will use\n",
    "import seaborn as sns        # seaborn graphical package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering: a type of unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using sklearn's pre-loaded data set \"20 Newsgroups\" \n",
    "- Code below is adapted from sklearn's official tutorial: \n",
    "  http://scikit-learn.org/stable/auto_examples/text/document_clustering.html \n",
    "\n",
    "Topic-based clustering is our goal:  \n",
    "- Given a set of documents that are written on 4 topics, can they be grouped into 4 clusters? \n",
    "\n",
    "We will try **K-means clustering** method. \n",
    "- A good introduction article: https://www.datascience.com/blog/k-means-clustering\n",
    "- sklearn's documentation: http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_iris.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TfidfVectorizer is essentially CountVectorizer + TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    # gets number count and then tfidf transformer in 1 step with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# We will use the same 4 categories\n",
    "cats = ['talk.religion.misc', 'soc.religion.christian', 'sci.space', 'comp.graphics']\n",
    "\n",
    "# Not using train-test split. Because this is un-supervised! \n",
    "dataset = fetch_20newsgroups(subset='all', categories=cats, shuffle=True, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'sklearn.datasets.base.Bunch'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'description', 'filenames', 'target', 'target_names']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: vis@world.std.com (Tom R Courtney)\\nSubject: Re: Space Marketing would be wonderfull.\\nOrganization: The World Public Access UNIX, Brookline, MA\\nLines: 17\\n\\nIn some sense, I think that the folks who think the idea is wonderful, and the\\nfolks who want to boycott anyone who has anything to do with this project are\\nboth right.\\n\\nThat is, I think that space advertising is an interesting idea, and if someone\\nwants to try it out, more power to them. However, a company may discover that\\nthe cost of launch is not the only cost of advertising, and a company who \\ngauged that ill will would lose them more revenue than the advertising would\\ngain might decide to bow out of the project.\\n\\nI got incensed when I read that Carl Sagan called this idea an \"abomination.\" \\nI don\\'t think that word means what he thinks it does. Children starving in the\\nrichest country in the world is an abomination; an ad agency is at worst just\\nin poor taste.\\n\\nTom Courtney\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, ..., 3, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['comp.graphics', 'sci.space', 'soc.religion.christian', 'talk.religion.misc']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.target\n",
    "dataset.target[5]\n",
    "dataset.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3585"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# In our case, WE KNOW TRUE VALUE OF K: 4 topics. \n",
    "# But in many real-life use cases, true number of clusters will not be known,\n",
    "#  and user must experiment with different K values. \n",
    "\n",
    "true_k = np.unique(dataset.target).shape[0]\n",
    "print(true_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ignore words found in over 50% of documents, ignore words found in just 1 document. \n",
    "# 1000 most frequent words, remove stop words. \n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, max_features=1000, stop_words='english')\n",
    "X = vectorizer.fit_transform(dataset.data)\n",
    "# uses sklearn's default tokenizer\n",
    "\n",
    "# words that are too common aren't helpful in discerning topic, so throw away words in more than 1/2 of the docs\n",
    "# only using the top 1000 words\n",
    "\n",
    "\n",
    "# turned text into sparse vector notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 31 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 204)\t0.0672523411448\n",
      "  (0, 746)\t0.105033387862\n",
      "  (0, 180)\t0.137895061559\n",
      "  (0, 899)\t0.318946488968\n",
      "  (0, 826)\t0.194510523256\n",
      "  (0, 289)\t0.0790109160299\n",
      "  (0, 292)\t0.0753453600121\n",
      "  (0, 474)\t0.0720597593222\n",
      "  (0, 382)\t0.117968021464\n",
      "  (0, 711)\t0.103870512588\n",
      "  (0, 957)\t0.0980917306138\n",
      "  (0, 982)\t0.271846319562\n",
      "  (0, 697)\t0.124447255719\n",
      "  (0, 53)\t0.118728321999\n",
      "  (0, 923)\t0.138473219002\n",
      "  (0, 16)\t0.124447255719\n",
      "  (0, 787)\t0.131302647881\n",
      "  (0, 887)\t0.313694855686\n",
      "  (0, 429)\t0.351672218256\n",
      "  (0, 689)\t0.265838807771\n",
      "  (0, 449)\t0.130831997331\n",
      "  (0, 959)\t0.153887024417\n",
      "  (0, 909)\t0.119059351145\n",
      "  (0, 671)\t0.12915907751\n",
      "  (0, 216)\t0.297109201319\n",
      "  (0, 235)\t0.280127897997\n",
      "  (0, 495)\t0.14325935292\n",
      "  (0, 160)\t0.116086406394\n",
      "  (0, 977)\t0.120763749157\n",
      "  (0, 553)\t0.122679382187\n",
      "  (0, 60)\t0.155757332972\n"
     ]
    }
   ],
   "source": [
    "X[5]\n",
    "print(X[5])\n",
    "# 1x1000? \"sparse matrix\"? \n",
    "\n",
    "# looking at one doc, with 1000 features\n",
    "# only contains 31 \"yes in this document\" features\n",
    "\n",
    "# sparse matrix, because instead of showing all 1000 spaces, stores the values that are in the document in sparse matrix\n",
    "# 31 calues that are part of top 1000 that aren't stop words\n",
    "\n",
    "# shows location and tfidf value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "826"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'com'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'children'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_.get('space')\n",
    "vectorizer.get_feature_names()[204]\n",
    "vectorizer.get_feature_names()[180]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation complete. Time to apply K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 6531.503\n",
      "Iteration  1, inertia 3381.913\n",
      "Iteration  2, inertia 3347.023\n",
      "Iteration  3, inertia 3328.463\n",
      "Iteration  4, inertia 3317.935\n",
      "Iteration  5, inertia 3315.324\n",
      "Iteration  6, inertia 3314.853\n",
      "Iteration  7, inertia 3314.743\n",
      "Iteration  8, inertia 3314.682\n",
      "Iteration  9, inertia 3314.642\n",
      "Iteration 10, inertia 3314.627\n",
      "Iteration 11, inertia 3314.622\n",
      "Iteration 12, inertia 3314.619\n",
      "Converged at iteration 12: center shift 0.000000e+00 within tolerance 9.553371e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=4, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1, verbose=True)\n",
    "km.fit(X)\n",
    "\n",
    "# true_k is 4 clusters\n",
    "# don't want to iterate a lot, so won't go past 100\n",
    "# verbose prints out log messages to tell you what to algorthim is doing\n",
    "\n",
    "\n",
    "# between each iteration, tells you how good it is\n",
    "# if it sees it won't get much better it will stop there\n",
    "    # everyone willl have different number of iterations becausee the centroids start at random places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.453\n",
      "Completeness: 0.465\n",
      "V-measure: 0.459\n",
      "Adjusted Rand-Index: 0.456\n",
      "Silhouette Coefficient: 0.016\n"
     ]
    }
   ],
   "source": [
    "# A bunch of metrics that compare target labels and labels as assigned by KM. \n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(dataset.target, km.labels_)) # labels as predicted by cluserting algorithm\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(dataset.target, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(dataset.target, km.labels_))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(dataset.target, km.labels_))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, km.labels_, sample_size=1000))\n",
    "\n",
    "# clustering gives labels (0,1,2,3)\n",
    "\n",
    "# these numbers mean something, but....\n",
    "    # need to know how to what the method is good for, what parameters it needs\n",
    "    # need to use method in the right way\n",
    "    \n",
    "        # then you can claim you know how to use K-means-clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0: graphics university posting host nntp thanks image ac uk computer\n",
      "Cluster 1: god jesus people christian church bible christ christians believe sin\n",
      "Cluster 2: space nasa henry access digex gov toronto pat alaska shuttle\n",
      "Cluster 3: com sandvik article kent apple netcom ibm don koresh newton\n"
     ]
    }
   ],
   "source": [
    "# Top terms (\"features\") as ranked by centroids\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()\n",
    "    \n",
    "# found space, computer graphics, and a religion one, and on that seems prety random\n",
    "# clustering algorythm doesn't know what it's clustering about\n",
    "\n",
    "# (cluster number doesn't correspond to target labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 0, 2, 1, 2, 1, 0, 0, 0, 1, 2, 3, 3, 3, 0, 1, 0, 3, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 2, 1, 2, 2, 2, 0, 2, 1, 2, 3, 2, 0, 3, 2, 3, 0], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['comp.graphics', 'sci.space', 'soc.religion.christian', 'talk.religion.misc']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.labels_[:20]        # Cluster labels as assigned by KMeans\n",
    "dataset.target[:20]    # These are the real target labels\n",
    "dataset.target_names\n",
    "\n",
    "# Cluster 0 is graphics, target label 0\n",
    "# Cluster 1 is relig Chris, target label 2\n",
    "# cluster 2 is space, target label 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 2. Let's try 3 clusters this time. \n",
    "\n",
    "- could be better to have 1 religion cluster even though origianlly given 4, beacuse the 2 religion ones are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 6556.930\n",
      "Iteration  1, inertia 3361.587\n",
      "Iteration  2, inertia 3338.413\n",
      "Iteration  3, inertia 3336.083\n",
      "Iteration  4, inertia 3335.352\n",
      "Iteration  5, inertia 3335.115\n",
      "Iteration  6, inertia 3334.988\n",
      "Iteration  7, inertia 3334.898\n",
      "Iteration  8, inertia 3334.861\n",
      "Iteration  9, inertia 3334.832\n",
      "Iteration 10, inertia 3334.821\n",
      "Iteration 11, inertia 3334.812\n",
      "Iteration 12, inertia 3334.804\n",
      "Iteration 13, inertia 3334.798\n",
      "Converged at iteration 13: center shift 0.000000e+00 within tolerance 9.553371e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=3, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km2 = KMeans(n_clusters=3, init='k-means++', max_iter=100, n_init=1, verbose=True)\n",
    "km2.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0: com graphics university posting host nntp thanks image computer ac\n",
      "Cluster 1: space nasa access henry digex gov pat toronto com alaska\n",
      "Cluster 2: god jesus com people christian church christians bible christ don\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km2.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(3):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()\n",
    "# Are the clusters looking better? \n",
    "# CAVEAT: could be local optimum, re-run to change\n",
    "\n",
    "# i re-ran it a second time because church and christian were in the graphics one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 2, 1, 2, 1, 0, 2, 2, 1, 2, 0, 1, 0, 2, 1, 0, 0, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 2, 1, 2, 2, 2, 0, 2, 1, 2, 3, 2, 0, 3, 2, 3, 0], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['comp.graphics', 'sci.space', 'soc.religion.christian', 'talk.religion.misc']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km2.labels_[:20]        # Cluster labels as assigned by KMeans\n",
    "dataset.target[:20]     # These are the real target labels\n",
    "dataset.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 2, 1, 2, 1, 2, 2, 2, 0, 2, 1, 2, 2, 2, 0, 2, 2, 2, 0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Newsgroup label -> KM label. Will need to adjust. \n",
    "labelmap = {0:0, 1:1, 2:2, 3:2}\n",
    "\n",
    "target_conv = [labelmap[x] for x in dataset.target]\n",
    "target_conv[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 961,    9,    3],\n",
       "       [ 232,  747,    8],\n",
       "       [ 272,    7, 1346]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(target_conv, km2.labels_)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot object at 0x0000026312DE3748>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text object at 0x00000263127AF668>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text object at 0x0000026312DEB9E8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAFXCAYAAAAWMQ0YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwADiCgAGEFcAMIC4AoAB/w95qbYDy+ECUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure object at 0x0000026312E08E10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true group')\n",
    "plt.ylabel('predicted group')\n",
    "plt.show()\n",
    "\n",
    "# tended to get predicted as computer graphics\n",
    "# clustering overpredicted to be part of computer category\n",
    "\n",
    "# good for unsupervised learning because didn't have access to true labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Can we produce nifty clustering visuals\n",
    "such as the ones in tutorial/documentation: \n",
    "- https://www.datascience.com/blog/k-means-clustering\n",
    "- http://scikit-learn.org/stable/_images/sphx_glr_plot_cluster_iris_004.png\n",
    "\n",
    "??\n",
    "\n",
    "Answer: NO - because we have 1000 features instead of 2-4\n",
    "\n",
    "\n",
    "Linguistic data has so many features; text based ML is very different from other types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Too Many Dimensions\n",
    "This is where PCA (Principal Component Analysis) comes in. \n",
    "- Textbook chapter: https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "skim through this chapter ^^     PCA helps with removing irrelevant features\n",
    "\n",
    "More notes from Lecture: \n",
    "\n",
    "some dimensions are very low in predictive power\n",
    "\n",
    "- we had 1000 features: can we go through and get rid of not-very-meaningful words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on new, made up examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'sending a payload to the ISS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-c5f400412b1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtests\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'sending a payload to the ISS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'I met Santa Claus once'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkm2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtests\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#???\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sigmo\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    955\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cluster_centers_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    958\u001b[0m         \u001b[0mx_squared_norms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_labels_inertia\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_squared_norms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sigmo\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36m_check_test_data\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m         \u001b[0mexpected_n_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sigmo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    380\u001b[0m                                       force_all_finite)\n\u001b[0;32m    381\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'sending a payload to the ISS'"
     ]
    }
   ],
   "source": [
    "# this worked in machine learning 1 but NOT here\n",
    "    # because the model was built as a pipeline \n",
    "        # model=make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "tests = ['sending a payload to the ISS', 'I met Santa Claus once']\n",
    "preds = km2.predict(tests)\n",
    "print(preds)\n",
    "#???\n",
    "\n",
    "# km2 doesn't take direct texts: we trained it on the sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "tests = ['sending a payload to the ISS space austronaut earth orbit', 'pray jesus I met Santa Claus once']\n",
    "tests_tfidf = vectorizer.transform(tests)    # Yep, need this\n",
    "preds = km2.predict(tests_tfidf)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
